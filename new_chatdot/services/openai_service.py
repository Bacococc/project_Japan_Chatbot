import openai
import os
import logging
from dotenv import load_dotenv
import time

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# OpenAI API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("Missing OpenAI API key. Please check your .env file.")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± (v1.0.0 ì´í›„ ë°©ì‹)
client = openai.OpenAI(api_key=OPENAI_API_KEY)

# ë™ê¸° ì¬ì‹œë„ ë¡œì§
def send_request_with_retry(request_function, retries=3, delay=5):
    for i in range(retries):
        try:
            return request_function()
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            if i < retries - 1:
                logger.warning(f"Retrying in {delay} seconds...")
                time.sleep(delay)
            else:
                logger.error("Maximum retries reached, unable to complete the request.")
                raise

# OpenAI ì‘ë‹µ í•¨ìˆ˜ (ëŒ€í™” ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±)
def get_openai_response(conversation_history, use_dummy=False):
    if use_dummy:
        # ë”ë¯¸ í…ìŠ¤íŠ¸ ë°˜í™˜
        return "ã“ã‚Œã¯ãƒ€ãƒŸãƒ¼ã®å¿œç­”ã§ã™ã€‚å®Ÿéš›ã®AIå¿œç­”ã®ä»£ã‚ã‚Šã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ğŸ˜Š"
    
    def request():
        try:
            # OpenAI API í˜¸ì¶œ (v1.0.0 ë°©ì‹)
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",  # GPT ëª¨ë¸ ì§€ì •
                messages=conversation_history,  # ëŒ€í™” ì´ë ¥ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
                max_tokens=100,  # ì‘ë‹µ ê¸¸ì´ ì œí•œ
                temperature=0.7  # ì°½ì˜ì ì¸ ë‹µë³€ì„ ìœ„í•œ ì˜¨ë„ ì„¤ì •
            )

            # ì‘ë‹µ ë‚´ìš© ì¶”ì¶œ
            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"Error during OpenAI request: {e}")
            raise

    # ì¬ì‹œë„ ë¡œì§ ì ìš©
    return send_request_with_retry(request)